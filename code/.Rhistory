## x0.mu   -0.682
## Initial states (x0) defined at t=0
## Standard errors have not been calculated.
## Use MARSSparamCIs to compute CIs and bias estimates.
### CREATE ILLUSTRATIVE FIGURE
# run multiple simulations
var_obs_values = seq(0, 2, length.out = 100)
results = matrix(NA, nrow = length(var_obs_values), ncol = 4)
colnames(results) = c("True", "StructTS", "MARSS_kem", "MARSS_BFGS")
for (i in seq_along(var_obs_values)) {
var_obs <- var_obs_values[i]
y <- simu_rwd_with_obs_error(N = 1400,
d = d,var_innov = var_innov, var_obs = var_obs)
out.sts = rwd_with_obs_error(y)
out.marss = rwd_with_obs_error_marss(y)
out.bfgs = rwd_with_obs_error_marss_bfgs(y)
results[i, "True"] = var_obs
results[i, "StructTS"] = out.sts["var_obs"]
results[i, "MARSS_kem"] <- out.marss["var_obs"]
results[i, "MARSS_BFGS"] <- out.bfgs["var_obs"]
}
rbind(out.sts, out.marss, out.bfgs)
d = .1073
var_innov = .1118
var_obs = 0.001
## standard example
y <- simu_rwd_with_obs_error(N = 1400,
d = d,var_innov = var_innov, var_obs = var_obs)
plot(y)
( out <- rwd_with_obs_error(y) )
##         d var_innov   var_obs
## 0.3794464 2.2167909 1.1101556
out.sts = rwd_with_obs_error(y)
out.marss = rwd_with_obs_error_marss(y)
out.bfgs = rwd_with_obs_error_marss_bfgs(y)
rbind(out.sts, out.marss, out.bfgs)
### CREATE ILLUSTRATIVE FIGURE
# run multiple simulations
var_obs_values = seq(0, 1, length.out = 100)
results = matrix(NA, nrow = length(var_obs_values), ncol = 4)
colnames(results) = c("True", "StructTS", "MARSS_kem", "MARSS_BFGS")
for (i in seq_along(var_obs_values)) {
var_obs <- var_obs_values[i]
y <- simu_rwd_with_obs_error(N = 1400,
d = d,var_innov = var_innov, var_obs = var_obs)
out.sts = rwd_with_obs_error(y)
out.marss = rwd_with_obs_error_marss(y)
out.bfgs = rwd_with_obs_error_marss_bfgs(y)
results[i, "True"] = var_obs
results[i, "StructTS"] = out.sts["var_obs"]
results[i, "MARSS_kem"] <- out.marss["var_obs"]
results[i, "MARSS_BFGS"] <- out.bfgs["var_obs"]
}
# run multiple simulations
var_obs_values = seq(0, 1, length.out = 200)
d = .1 # the rounded average estimated drift from the state models (original spec was  .4)
var_innov = .1 # the rounded average estimated var_innov from the state models (original spec was 2)
var_obs = 0.001
var_obs_values = seq(0, 1, length.out = 200)
results = matrix(NA, nrow = length(var_obs_values), ncol = 4)
colnames(results) = c("True", "StructTS", "MARSS_kem", "MARSS_BFGS")
for (i in seq_along(var_obs_values)) {
var_obs <- var_obs_values[i]
y <- simu_rwd_with_obs_error(N = 1400,
d = d,var_innov = var_innov, var_obs = var_obs)
out.sts = rwd_with_obs_error(y)
out.marss = rwd_with_obs_error_marss(y)
out.bfgs = rwd_with_obs_error_marss_bfgs(y)
results[i, "True"] = var_obs
results[i, "StructTS"] = out.sts["var_obs"]
results[i, "MARSS_kem"] <- out.marss["var_obs"]
results[i, "MARSS_BFGS"] <- out.bfgs["var_obs"]
}
var_obs_values = seq(0, .5, length.out = 100)
results = matrix(NA, nrow = length(var_obs_values), ncol = 4)
colnames(results) = c("True", "StructTS", "MARSS_kem", "MARSS_BFGS")
for (i in seq_along(var_obs_values)) {
var_obs <- var_obs_values[i]
y <- simu_rwd_with_obs_error(N = 1400,
d = d,var_innov = var_innov, var_obs = var_obs)
out.sts = rwd_with_obs_error(y)
out.marss = rwd_with_obs_error_marss(y)
out.bfgs = rwd_with_obs_error_marss_bfgs(y)
results[i, "True"] = var_obs
results[i, "StructTS"] = out.sts["var_obs"]
results[i, "MARSS_kem"] <- out.marss["var_obs"]
results[i, "MARSS_BFGS"] <- out.bfgs["var_obs"]
}
View(state_data)
test = read.table(comp8090.txt)
#### ENTIRE US ####
# read in life tables for US
path = "/Users/paigepark/Desktop/us-mortality/data"
test = read.table(comp8090.txt)
test = read.table("comp8090.txt")
getwd()
test = read.table(paste(path, "comp8090.txt"))
test = read.table(paste(path, "comp8090.txt", sep="\"))
test = read.table(paste(path, "comp8090.txt", sep="/"))
test = read.table(paste(path, "comp8090.txt", sep="/"))
test2 = read.table(paste(path, "comp8090.txt", sep="/"))
# Read the first 5 lines of the file
head(readLines(paste(path, "comp8090.txt", sep="/")), 5)
# Read the first 5 lines of the file
head(readLines(paste(path, "state_pop_1989.txt", sep="/")), 5)
lines = readLines(paste(path, "state_pop_1989.txt", sep="/"))
lines <- lines[nzchar(lines)]
# Remove lines without numbers
lines <- lines[grep("[0-9]", lines)]
# Combine the lines back into a single string, with lines separated by "\n"
table_text <- paste(lines, collapse = "\n")
# Use the textConnection function to treat the string as a file
table_conn <- textConnection(table_text)
# Read the table data from the "file"
table_data <- read.table(table_conn)
# get estimate for N: I use the populations from the mid-point year of the time series (1989)
pop_89 = read.csv(paste(path, "89_pop.csv"), header = TRUE)
# get estimate for N: I use the populations from the mid-point year of the time series (1989)
pop_89 = read.csv(paste(path, "89_pop.csv", sep = "/"), header = TRUE)
View(pop_89)
# get estimate for N: I use the populations from the mid-point year of the time series (1989)
pop_89 = read.csv(paste(path, "89_pop.csv", sep = "/"), header = TRUE, row.names = 1)
View(pop_89)
# get estimate for N: I use the populations from the mid-point year of the time series (1989)
pop_89 = read.csv(paste(path, "89_pop.csv", sep = "/"), header = TRUE, row.names = 1)[,5]
# get estimate for N: I use the populations from the mid-point year of the time series (1989)
pop_89 = read.csv(paste(path, "89_pop.csv", sep = "/"), header = TRUE, row.names = 1)
pop_89 = pop_89["Jul.89"]
View(pop_89)
samp_var = 150/pop_89
View(samp_var)
150/300000000
View(state_sts)
# StructTS table
state.sts = as.data.frame(t(state.sts))
# StructTS table
state_sts = as.data.frame(t(state_sts))
View(state_sts)
state_sts = matrix(NA, nrow=50, ncol=3)
state_sts = as.data.frame(apply(state_e0, 1, rwd_with_obs_error))
# results in 13 states with 0 observation variance
# help p
state_sts = t(state_sts)
state_sts = as.data.frame(cbind(state_sts, samp_var))
samp_var = 150/pop_89
samp_var = samp_var[-1]
View(samp_var)
View(samp_var)
samp_var = 150/pop_89
View(samp_var)
samp_var = 150/pop_89
samp_var = samp_var[!(rownames(samp_var) %in% c("US", "DC")), ]
samp_var = 150/pop_89
samp_var = subset(samp_var, !(rownames(samp_var) %in% c("US", "DC")))
state_sts = t(state_sts)
state_sts = as.data.frame(cbind(state_sts, samp_var))
# StructTS table
state_sts = t(state_sts)
state_sts = as.data.frame(cbind(state_sts, samp_var))
colnames(state_sts) = c("drift", "process SD", "shock SD", "sampling SD")
colnames(state_sts) = c("drift", "process_SD", "shock_SD", "sampling_SD")
state_sts = as.data.frame(apply(state_e0, 1, rwd_with_obs_error))
state_sts = t(state_sts)
state_sts = as.data.frame(cbind(state_sts, samp_var))
samp_SD = 150/pop_89
samp_SD = subset(samp_var, !(rownames(samp_var) %in% c("US", "DC")))
state_sts = as.data.frame(apply(state_e0, 1, rwd_with_obs_error))
samp_sd = 150/pop_89
samp_sd = subset(samp_sd, !(rownames(samp_sd) %in% c("US", "DC")))
# StructTS table
state_sts_table = t(state_sts)
state_sts_table = as.data.frame(cbind(state_sts_table, samp_sd))
View(state_sts_table)
state_sts_table = state_sts_table %>%
mutate(process_sd = sqrt(var_innov), shock_sd = sqrt(var_obs)) %>%
mutate(shock_sd = shock_sd - Jul.89)
state_sts_table = t(state_sts)
state_sts_table = as.data.frame(cbind(state_sts_table, samp_sd))
state_sts_table = state_sts_table %>%
mutate(var_innov = sqrt(var_innov), var_obs = sqrt(var_obs)) %>%
mutate(var_obs = var_obs - Jul.89)
colnames(state_sts_table) = c("drift", "process_SD", "shock_SD", "sampling_SD")
state_no_obs_sts = which(state_sts[3,]==0)
state_no_obs_sts = colnames(state_sts)[state_no_obs_sts]
state_no_obs_sts
if (state_sts_table$shock_SD < 0) {state_sts_table$shock_SD == NA}
state_sts_table$shock_SD <- ifelse(state_sts_table$shock_SD < 0, NA, state_sts_table$shock_SD)
View(state_sts_table)
# get latex code
library(stargazer)
stargazer(state_sts_table, type="latex")
stargazer(state_sts_table, title = "StructTS Results", summary = FALSE, type="latex")
stargazer(state_sts_table, title = "StructTS Results", summary = FALSE, na.string = "NA", type="latex")
stargazer(state_sts_table, title = "StructTS Results", summary = FALSE, type="latex")
rwd_with_obs_error_bfgs <- function(y, ...)
{
library(MARSS)
mod.list.2 <- list(B = matrix(1),
U = matrix("d"),
Q = matrix("q"),
Z = matrix(1),
A = matrix(0),
R = matrix("r"),
x0 = matrix("mu"),
tinitx = 0)
out2.marss = MARSS(y, model = mod.list.2, control=list(maxit=1000), method= "BFGS", ...)
if (out2.marss$convergence == 0) {
d = coef(out2.marss)$U[1,1]
var_innov = coef(out2.marss)$Q[1,1]
var_obs = coef(out2.marss)$R[1,1]
} else {
d = NA
var_innov = NA
var_obs = NA
}
names(d) <- names(var_innov) <- names(var_obs) <- ""
return(c(d= d,
var_innov= var_innov,
var_obs = var_obs))
}
rwd_with_obs_error_kem <- function(y, ...)
{
library(MARSS)
mod.list.2 <- list(B = matrix(1),
U = matrix("d"),
Q = matrix("q"),
Z = matrix(1),
A = matrix(0),
R = matrix("r"),
x0 = matrix("mu"),
tinitx = 0)
out2.marss = MARSS(y, model = mod.list.2, control=list(maxit=1000), method= "kem", ...)
if (out2.marss$convergence == 0) {
d = coef(out2.marss)$U[1,1]
var_innov = coef(out2.marss)$Q[1,1]
var_obs = coef(out2.marss)$R[1,1]
} else {
d = NA
var_innov = NA
var_obs = NA
}
names(d) <- names(var_innov) <- names(var_obs) <- ""
return(c(d= d,
var_innov= var_innov,
var_obs = var_obs))
}
state_kem = matrix(NA, nrow=50, ncol=3)
state_kem = as.data.frame(apply(state_e0, 1, rwd_with_obs_error_kem))
# results in 6 states with 0 observation variance when used with "kem" method
# MARSS BFGS
state_bfgs = matrix(NA, nrow=50, ncol=3)
state_bfgs = as.data.frame(apply(state_e0, 1, rwd_with_obs_error_bfgs))
state_bfgs_table = t(state_bfgs)
state_bfgs_table = as.data.frame(cbind(state_bfgs_table, samp_sd))
state_bfgs_table = state_bfgs_table %>%
mutate(var_innov = sqrt(var_innov), var_obs = sqrt(var_obs)) %>%
mutate(var_obs = var_obs - Jul.89)
colnames(state_bfgs_table) = c("drift", "process_SD", "shock_SD", "sampling_SD")
state_bfgs_table$shock_SD <- ifelse(state_bfgs_table$shock_SD < 0, NA, state_bfgs_table$shock_SD)
View(state_bfgs_table)
# get latex code for MARSS BFGS
stargazer(state_bfgs_table, title = "MARSS BFGS Results", summary = FALSE, type="latex")
state_kem_table = t(state_kem)
state_kem_table = as.data.frame(cbind(state_kem_table, samp_sd))
state_kem_table = state_kem_table %>%
mutate(var_innov = sqrt(var_innov), var_obs = sqrt(var_obs)) %>%
mutate(var_obs = var_obs - Jul.89)
colnames(state_kem_table) = c("drift", "process_SD", "shock_SD", "sampling_SD")
state_kem_table$shock_SD <- ifelse(state_kem_table$shock_SD < 0, NA, state_kem_table$shock_SD)
# get latex code for MARSS BFGS
stargazer(state_kem_table, title = "MARSS BFGS Results", summary = FALSE, type="latex")
# this code is currently giving blanks instead of NAs - fix later
# get latex code for MARSS KEM
stargazer(state_kem_table, title = "MARSS KEM Results", summary = FALSE, type="latex")
if (!requireNamespace("keras", quietly = TRUE)) {
install.packages("keras")
}
library(keras)
#library(whereami)
# setting up path
script_dir <- getwd()
path <- file.path(script_dir, "data/Mx_1x1") # make reproducible later
path
library(whereami)
# setting up path
script_dir <- whereami()
# setting up path
script_dir <- whereami()
path <- file.path(script_dir, "../../data/Mx_1x1")
path <- normalize(path)
path <- normalizePath(path)
# read in data
countries <- c("AUS", "AUT", "BEL", "BGR", "BLR", "CAN", "CHE", "CZE",
"DNK", "ESP", "EST", "FIN", "FRATNP", "GBRTENW",
"GBR_NIR", "GBR_SCO", "GRC", "HUN", "IRL", "ISL",
"ISR", "ITA", "JPN", "LTU", "LUX", "LVA", "NLD", "NOR",
"NZL_NM", "POL", "PRT", "RUS", "SVK", "SVN", "SWE", "TWN",
"UKR", "USA")
country_data <- list()
for (i in 1:length(countries)){
file <- paste(countries[i], "Mx_1x1.txt", sep = ".")
country_data[[i]] <- read.table(paste(path, file, sep = "/"))
}
for (i in 1:length(countries)){
file <- paste(countries[i], "Mx_1x1.txt", sep = ".")
country_data[[i]] <- read.table(paste(path, file, sep = "/"),
header = TRUE,
skip = 2,
sep = "",
stringsAsFactors = FALSE)
}
View(country_data)
names(country_data) <- countries
View(country_data)
View(country_data)
library(tidyverse)
model <- keras_model(inputs = c(Year, Age, Country, Gender), outputs = c(main_output))
# installing and loading packages
if (!requireNamespace("keras", quietly = TRUE)) {
install.packages("keras")
}
library(keras)
library(whereami)
library(tidyverse)
# setting up path
script_dir <- whereami()
path <- file.path(script_dir, "../../data/Mx_1x1")
path <- normalizePath(path)
path
# read in data
countries <- c("AUS", "AUT", "BEL", "BGR", "BLR", "CAN", "CHE", "CZE",
"DNK", "ESP", "EST", "FIN", "FRATNP", "GBRTENW",
"GBR_NIR", "GBR_SCO", "GRC", "HUN", "IRL", "ISL",
"ISR", "ITA", "JPN", "LTU", "LUX", "LVA", "NLD", "NOR",
"NZL_NM", "POL", "PRT", "RUS", "SVK", "SVN", "SWE", "TWN",
"UKR", "USA")
country_data <- list()
for (i in 1:length(countries)){
file <- paste(countries[i], "Mx_1x1.txt", sep = ".")
country_data[[i]] <- read.table(paste(path, file, sep = "/"),
header = TRUE,
skip = 2,
sep = "",
stringsAsFactors = FALSE)
}
names(country_data) <- countries
### setting up DEEP6 (deep neural network with tanh activations)
# defining inputs
Year <- layer_input(shape = c(1), dtype = 'float32', name = 'Year')
# installing and loading packages
library(keras)
library(tensorflow)
library(whereami)
library(tidyverse)
# setting up path
script_dir <- whereami()
path <- file.path(script_dir, "../../data/Mx_1x1")
path <- normalizePath(path)
path
# read in data
countries <- c("AUS", "AUT", "BEL", "BGR", "BLR", "CAN", "CHE", "CZE",
"DNK", "ESP", "EST", "FIN", "FRATNP", "GBRTENW",
"GBR_NIR", "GBR_SCO", "GRC", "HUN", "IRL", "ISL",
"ISR", "ITA", "JPN", "LTU", "LUX", "LVA", "NLD", "NOR",
"NZL_NM", "POL", "PRT", "RUS", "SVK", "SVN", "SWE", "TWN",
"UKR", "USA")
country_data <- list()
for (i in 1:length(countries)){
file <- paste(countries[i], "Mx_1x1.txt", sep = ".")
country_data[[i]] <- read.table(paste(path, file, sep = "/"),
header = TRUE,
skip = 2,
sep = "",
stringsAsFactors = FALSE)
}
names(country_data) <- countries
### setting up DEEP6 (deep neural network with tanh activations)
# defining inputs
Year <- layer_input(shape = c(1), dtype = 'float32', name = 'Year')
tensorflow::install_tensorflow()
# setting up path
script_dir <- whereami()
path <- file.path(script_dir, "../../data/Mx_1x1")
path <- normalizePath(path)
path
# read in data
countries <- c("AUS", "AUT", "BEL", "BGR", "BLR", "CAN", "CHE", "CZE",
"DNK", "ESP", "EST", "FIN", "FRATNP", "GBRTENW",
"GBR_NIR", "GBR_SCO", "GRC", "HUN", "IRL", "ISL",
"ISR", "ITA", "JPN", "LTU", "LUX", "LVA", "NLD", "NOR",
"NZL_NM", "POL", "PRT", "RUS", "SVK", "SVN", "SWE", "TWN",
"UKR", "USA")
country_data <- list()
for (i in 1:length(countries)){
file <- paste(countries[i], "Mx_1x1.txt", sep = ".")
country_data[[i]] <- read.table(paste(path, file, sep = "/"),
header = TRUE,
skip = 2,
sep = "",
stringsAsFactors = FALSE)
}
names(country_data) <- countries
### setting up DEEP6 (deep neural network with tanh activations)
# defining inputs
Year <- layer_input(shape = c(1), dtype = 'float32', name = 'Year')
Age <- layer_input(shape = c(1), dtype = 'int32', name = 'Age')
Country <- layer_input(shape = c(1), dtype = 'int32', name = 'Country')
Gender <- layer_input(shape = c(1), dtype = 'int32', name = 'Gender')
# defining embedding layers
# input data can take any integer value between 0 and 99
# each integer from the input will be mapped to vector of size 5
# each input sequence is a single integer
# summary: building layer that takes integer inputs representing age, gender,
# and country and embeds them into a dense space of 5 dimensions
# then flattens the output
Age_embed = Age %>%
layer_embedding(input_dim = 100, output_dim = 5, input_length = 1, name = 'Age_embed') %>%
keras::layer_flatten()
Gender_embed = Gender %>%
layer_embedding(input_dim = 100, output_dim = 5, input_length = 1, name = 'Gender_embed') %>%
keras::layer_flatten()
Country_embed = Country %>%
layer_embedding(input_dim = 100, output_dim = 5, input_length = 1, name = 'Country_embed') %>%
keras::layer_flatten()
# creating feature vector
features <- layer_concatenate(list(Year, Age_embed, Gender_embed, Country_embed))
# setting up middle layers
middle = features %>%
layer_dense(units = 128, activation = 'tanh') %>%
layer_batch_normalization() %>%
layer_droput(0.05) %>%
layer_dense(units = 128, activation = 'tanh') %>%
layer_batch_normalization() %>%
layer_droput(0.05) %>%
layer_dense(units = 128, activation = 'tanh') %>%
layer_batch_normalization() %>%
layer_droput(0.05) %>%
layer_dense(units = 128, activation = 'tanh') %>%
layer_batch_normalization() %>%
layer_droput(0.05)
# setting up middle layers
middle = features %>%
layer_dense(units = 128, activation = 'tanh') %>%
layer_batch_normalization() %>%
layer_dropout(0.05) %>%
layer_dense(units = 128, activation = 'tanh') %>%
layer_batch_normalization() %>%
layer_dropout(0.05) %>%
layer_dense(units = 128, activation = 'tanh') %>%
layer_batch_normalization() %>%
layer_dropout(0.05) %>%
layer_dense(units = 128, activation = 'tanh') %>%
layer_batch_normalization() %>%
layer_dropout(0.05)
# setting up output layer
main_output = layer_concatenate(list(features, middle)) %>%
layer_dense(units = 128, activation = 'tanh') %>%
layer_batch_normalization() %>%
layer_dropout(0.05) %>%
layer_dense(units = 1, activation = 'sigmoid', name = 'main_output')
model <- keras_model(inputs = c(Year, Age, Country, Gender), outputs = c(main_output))
summary(model)
summary(model)
# compiling the model
model %>% compile(loss = "mse",
optimizer = "adam",
metrics = c("accuracy"))
View(country_data)
country_data[["AUS"]][["Female"]]
country_data[["AUS"]]
View(country_data[["AUS"]])
View(country_data)
View(country_data[["AUT"]])
countries <- c("AUS", "AUT", "BEL", "BGR", "BLR", "CAN", "CHE", "CZE",
"DNK", "ESP", "EST", "FIN", "FRATNP", "GBRTENW",
"GBR_NIR", "GBR_SCO", "GRC", "HUN", "IRL", "ISL",
"ISR", "ITA", "JPN", "LTU", "LUX", "LVA", "NLD", "NOR",
"NZL_NM", "POL", "PRT", "RUS", "SVK", "SVN", "SWE", "TWN",
"UKR", "USA")
country_data <- list()
for (i in 1:length(countries)){
file <- paste(countries[i], "Mx_1x1.txt", sep = ".")
country_data[[i]] <- read.table(paste(path, file, sep = "/"),
header = TRUE,
skip = 2,
sep = "",
stringsAsFactors = FALSE)
country_data[[i]]$Country = countries[i]
}
names(country_data) <- countries
all_countries <- do.call(rbind, country_data)
View(all_countries)
# get gender variable and mort rate variable
all_countries_long <- all_countries %>%
gather(key = "Gender", value = "Mortality_rate", c("Female", "Male"))
View(all_countries)
View(all_countries_long)
# get gender variable and mort rate variable
all_countries_long <- all_countries %>%
gather(key = "Gender", value = "Mortality_rate", c("Female", "Male")) %>%
mutate(-Total)
# get gender variable and mort rate variable
all_countries_long <- all_countries %>%
gather(key = "Gender", value = "Mortality_rate", c("Female", "Male")) %>%
all_countries_long$Total <- NULL
all_countries_long$Total <- NULL
View(all_countries_long)
script_dir <- whereami()
path <- file.path(script_dir, "../../data/Mx_1x1")
path <- normalizePath(path)
path
write.csv(all_countries_long, paste(path, "hmd.csv", sep = "/"), row.names = FALSE)
